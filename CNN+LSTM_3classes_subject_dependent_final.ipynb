{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL0seVN-WOiP"
      },
      "source": [
        "Code for MohammadReza Safari's Thesis\n",
        "Dataset: STEW\n",
        "Analyze in 3classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWzslzxEWy4G"
      },
      "source": [
        "# Initializer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code has been run on google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd45MULkQJIw",
        "outputId": "51d5c356-bb1e-4d09-8444-2bb2848dcb1b"
      },
      "outputs": [],
      "source": [
        "# 1. mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVf95Ru9Rytp",
        "outputId": "0fb79bcb-f0c7-4150-897b-d41a125dc190"
      },
      "outputs": [],
      "source": [
        "# 2. set directory of data\n",
        "%cd /content/gdrive/My Drive/Thesis/dDTF_images\n",
        "base_dir='/content/gdrive/My Drive/Thesis/dDTF_images/3classes'\n",
        "\n",
        "freq_band = 'theta'\n",
        "\n",
        "# Define the checkpoint filepath for best model\n",
        "model_checkpoint_filepath = base_dir + '/best_model_3classes_' + freq_band + '_Resnet50LSTM' + '.h5'\n",
        "history_dir = base_dir + '/hist_Resnet50LSTM_3classes_SGD_' + freq_band\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrEa2N_mR0Bw"
      },
      "outputs": [],
      "source": [
        "# 3. import libraries\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet import ResNet50\n",
        "from keras.applications.efficientnet import EfficientNetB0\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Layer,Dense, Dropout, Input, Activation, TimeDistributed, Reshape\n",
        "from tensorflow.keras.layers import  GRU, Bidirectional\n",
        "from tensorflow.keras.layers import  Conv1D, Conv2D, MaxPooling2D, Flatten, BatchNormalization, LSTM, ZeroPadding2D, GlobalAveragePooling2D, SpatialDropout2D, GlobalMaxPool1D,Convolution1D\n",
        "from tensorflow.keras.callbacks import History\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.utils import np_utils\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from natsort import natsorted\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "import cv2\n",
        "import pickle\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQP-QqwAR1cw"
      },
      "outputs": [],
      "source": [
        "# 4. define some methods\n",
        "\n",
        "def smooth_curve(points, factor=0.2):\n",
        "  smoothed_points = []\n",
        "  for point in points:\n",
        "    if smoothed_points:\n",
        "      previous = smoothed_points[-1]\n",
        "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "    else:\n",
        "      smoothed_points.append(point)\n",
        "\n",
        "  return smoothed_points\n",
        "\n",
        "\n",
        "def plot_results(history):\n",
        "  acc = history.history['acc']\n",
        "  val_acc = history.history['val_acc']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "  %matplotlib inline\n",
        "  plt.plot(epochs, smooth_curve(acc), 'r', alpha = 0.6, label='Training acc')\n",
        "  plt.plot(epochs, smooth_curve(val_acc), 'b', alpha = 0.6, label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, smooth_curve(loss), 'r', alpha = 0.6, label='Training loss')\n",
        "  plt.plot(epochs, smooth_curve(val_loss), 'b', alpha = 0.6, label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "def plot_mean_of_all_folds(train_acc_list, val_acc_list, train_loss_list, val_loss_list):\n",
        "  # Plot the mean of training and validation accuracy across all folds\n",
        "  train_acc_mean = np.mean(train_acc_list, axis=0)\n",
        "  val_acc_mean = np.mean(val_acc_list, axis=0)\n",
        "  train_loss_mean = np.mean(train_loss_list, axis=0)\n",
        "  val_loss_mean = np.mean(val_loss_list, axis=0)\n",
        "  %matplotlib inline\n",
        "  plt.plot(train_acc_mean, 'r', alpha = 0.6, label='Training Accuracy')\n",
        "  plt.plot(val_acc_mean, 'b', alpha = 0.6, label='Validation Accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "  plt.plot(train_loss_mean, 'r', alpha = 0.6, label='Training loss')\n",
        "  plt.plot(val_loss_mean, 'b', alpha = 0.6, label='Validation loss')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# def calculate_test_accuracy(model, X_test, Y_test):\n",
        "#   fold_results = {}\n",
        "#   Y_test = np_utils.to_categorical(Y_test)\n",
        "#   predicted_probas = model.predict(np.array(X_test),steps = len(X_test))\n",
        "#   fold_results['predicted_probas'] = predicted_probas\n",
        "#   binary_prediction=[]\n",
        "#   binary_prediction0=[]\n",
        "#   for i in range(len(predicted_probas)):\n",
        "#     #  binary_prediction0 = 1 if predicted_probas[i]>=0.5 else 0\n",
        "#      binary_prediction0 = np.round(predicted_probas)\n",
        "#      binary_prediction.append(binary_prediction0)\n",
        "#   fold_results['binary_prediction'] = binary_prediction\n",
        "#   conf_mat = confusion_matrix(binary_prediction, Y_test)\n",
        "#   fold_results['confusion_matrix'] = conf_mat\n",
        "#   acc = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
        "#   fold_results['test_accuracy'] = acc\n",
        "#   print('Overall accuracy: {:.2f} %'.format(acc*100))\n",
        "#   return fold_results\n",
        "\n",
        "def test_accuracy(model, X_test, Y_test):\n",
        "  X_test = np.array(X_test)\n",
        "  Y_test = np.array(Y_test)\n",
        "\n",
        "  Y_test = np_utils.to_categorical(Y_test)\n",
        "  Y_pred = model.predict(X_test)\n",
        "  Y_pred = np.argmax(Y_pred, axis=1)\n",
        "  Y_test = np.argmax(Y_test, axis=1)\n",
        "  test_acc = accuracy_score(Y_pred,Y_test)\n",
        "  cm = confusion_matrix(Y_test, Y_pred)\n",
        "  plot_conf_mat(cm)\n",
        "\n",
        "  return test_acc, cm\n",
        "\n",
        "\n",
        "def plot_conf_mat(cm):\n",
        "  # Normalize the confusion matrix\n",
        "  cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "  conf_labels = ['low', 'moderate', 'high']\n",
        "  sns.heatmap(cm_norm, annot=True, cmap='Blues', fmt='.2%', xticklabels=conf_labels, yticklabels=conf_labels)\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('True')\n",
        "  plt.show()\n",
        "\n",
        "def get_model_metrics(cm):\n",
        "  TP = cm[0, 0]\n",
        "  FP = cm[0, 1]\n",
        "  FN = cm[1, 0]\n",
        "  TN = cm[1, 1]\n",
        "  sensitivity = TP / (TP + FN)\n",
        "  specificity = TN / (TN + FP)\n",
        "  precision = TP / (TP + FP)\n",
        "  FAR = FP / (FP + TN)\n",
        "  FRR = FN / (FN + TP)\n",
        "  print(\"Metrics:\")\n",
        "  print(f\"Sensitivity: {sensitivity:.2f}\")\n",
        "  print(f\"Specificity: {specificity:.2f}\")\n",
        "  print(f\"Precision: {precision:.2f}\")\n",
        "  print(f\"FAR: {FAR:.2f}\")\n",
        "  print(f\"FRR: {FRR:.2f}\")\n",
        "\n",
        "  return sensitivity, specificity, precision, FAR, FRR\n",
        "\n",
        "\n",
        "def create_model():\n",
        "  conv_base = ResNet50(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
        "  # conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
        "  # conv_base = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
        "\n",
        "  conv_base.trainable = True\n",
        "\n",
        "  model = models.Sequential()\n",
        "  model.add(conv_base)\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(32)) #,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-5)))\n",
        "\n",
        "  cnn = models.Model(model.input, model.output)\n",
        "\n",
        "  seq_input = Input(shape=(5,224,224,3))\n",
        "  encoded_sequence = TimeDistributed(cnn)(seq_input)\n",
        "  encoded_sequence = Bidirectional(LSTM(32, return_sequences=True))(encoded_sequence)\n",
        "\n",
        "  #encoded_sequence = Dropout(rate=0.1)(encoded_sequence)\n",
        "  encoded_sequence = Bidirectional(LSTM(32, return_sequences=False))(encoded_sequence)\n",
        "  out = Dense(3, activation=\"softmax\")(encoded_sequence)\n",
        "  #out = Convolution1D(1, kernel_size=1, activation=\"sigmoid\", padding=\"same\")(encoded_sequence)\n",
        "\n",
        "  cnn_lstm = models.Model(seq_input, out)\n",
        "  cnn_lstm.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(learning_rate=1e-4),metrics=['acc'])\n",
        "\n",
        "  if fold_count == 1:\n",
        "    cnn_lstm.summary()\n",
        "  return cnn_lstm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-lrsCPwR424"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNNgPMXmR3ng",
        "outputId": "12ca2ece-f13a-4f37-e360-317a309f6a13"
      },
      "outputs": [],
      "source": [
        "# 5. load images data from drive\n",
        "\n",
        "# hi_dir = base_dir + '/' + freq_band + '/hi'\n",
        "# hi_data = os.listdir(hi_dir)\n",
        "# hi_data = natsorted(hi_data)\n",
        "# print(np.array(hi_data).shape)\n",
        "\n",
        "# med_dir = base_dir + '/' + freq_band + '/med'\n",
        "# med_data = os.listdir(med_dir)\n",
        "# med_data = natsorted(med_data)\n",
        "# print(np.array(med_data).shape)\n",
        "\n",
        "# lo_dir = base_dir + '/' + freq_band + '/lo'\n",
        "# lo_data = os.listdir(lo_dir)\n",
        "# lo_data = natsorted(lo_data)\n",
        "# print(np.array(lo_data).shape)\n",
        "# print(np.shape(lo_data[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou7gqyUJR8uQ",
        "outputId": "0789f892-b524-4d6e-fc35-ae6a316e6ca8"
      },
      "outputs": [],
      "source": [
        "# 6. Resize images. this cell may take some times\n",
        "# print(freq_band)\n",
        "\n",
        "# X_q3 = []\n",
        "# for img in hi_data:\n",
        "#     with Image.open(hi_dir+\"/\"+img) as im:\n",
        "#       resized_im = im.resize((224,224))\n",
        "#       X_q3.append(resized_im)\n",
        "# print(np.shape(X_q3)) # (925,)\n",
        "\n",
        "\n",
        "# X_q2 = []\n",
        "# for img in med_data:\n",
        "#     with Image.open(med_dir+\"/\"+img) as im:\n",
        "#       resized_im = im.resize((224,224))\n",
        "#       X_q2.append(resized_im)\n",
        "# print(np.shape(X_q2)) # (851,)\n",
        "\n",
        "# X_q1 = []\n",
        "# for img in lo_data:\n",
        "#     with Image.open(lo_dir+\"/\"+img) as im:\n",
        "#       resized_im = im.resize((224,224))\n",
        "#       X_q1.append(resized_im)\n",
        "# print(np.shape(X_q1)) # (1554,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXmoBWL5R_Rg",
        "outputId": "387ebdac-0738-45c0-f061-4249e7b2571c"
      },
      "outputs": [],
      "source": [
        "# 7. create images_data that is a collection from all classes\n",
        "\n",
        "# Images_data = X_q1 + X_q2 + X_q3 # [lo,med,hi]\n",
        "# print(np.shape(Images_data)) # (3330,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-reJGlDkSAkX"
      },
      "outputs": [],
      "source": [
        "# 8. dump images_data as Images_data.\n",
        "\n",
        "# with open(base_dir+'/Images_data_3classes_' + freq_band, 'wb') as file_pi1:\n",
        "#     pickle.dump(Images_data, file_pi1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1M2ofwESCDH",
        "outputId": "b7247b20-090b-44f0-e403-ed3135bb9c19"
      },
      "outputs": [],
      "source": [
        "# 9. load the images_data from drive if you don't wanna run from first cell.\n",
        "\n",
        "with open(base_dir+'/Images_data_3classes_' + freq_band, 'rb') as f:\n",
        "    Images_data = pickle.load(f)\n",
        "\n",
        "print(np.shape(Images_data)) # (3330,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKt3C2m7YVJZ",
        "outputId": "c59a46f4-9d6d-4157-fd31-117c976ec2c4"
      },
      "outputs": [],
      "source": [
        "Images_data = [np.asarray(img) for img in Images_data]\n",
        "\n",
        "print(type(Images_data[0]));\n",
        "print(np.shape(Images_data[0]))\n",
        "print(np.shape(Images_data)) # (3330, 224, 224, 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdpuMiP8SEpC"
      },
      "source": [
        "Prepare the video samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0LTJcftSD7P",
        "outputId": "7637a5a9-6eca-4cbe-9b54-b4379efa27de"
      },
      "outputs": [],
      "source": [
        "# 11. If you start running from 9th cell you need run this cell to define X_q1 and X_q2\n",
        "\n",
        "X_q1 = Images_data[:37*42]\n",
        "X_q2 = Images_data[37*42:37*65]\n",
        "X_q3 = Images_data[37*65:]\n",
        "\n",
        "print(np.shape(X_q1[0]))\n",
        "print(np.shape(X_q1)) # (1554, 224, 224, 3)\n",
        "print(np.shape(X_q2)) # (851, 224, 224, 3)\n",
        "print(np.shape(X_q3)) # (925, 224, 224, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of9gW211uD0G",
        "outputId": "3e66c98a-f310-4be5-c040-4f7fc4f2db8b"
      },
      "outputs": [],
      "source": [
        "# separate 5 sub's data for test (sub: 1,2,6,7,8)\n",
        "\n",
        "X_q1_test_sub1 = X_q1[:37]\n",
        "X_q1_test_sub2 = X_q1[37:37*2]\n",
        "X_q1_test_sub6 = []\n",
        "X_q1_test_sub7 = X_q1[37*4:37*5]\n",
        "X_q1_test_sub8 = X_q1[37*5:37*6]\n",
        "\n",
        "X_q2_test_sub1 = []\n",
        "X_q2_test_sub2 = X_q2[:37]\n",
        "X_q2_test_sub6 = X_q2[37*3:37*4]\n",
        "X_q2_test_sub7 = X_q2[37*4:37*5]\n",
        "X_q2_test_sub8 = []\n",
        "\n",
        "X_q3_test_sub1 = X_q3[:37]\n",
        "X_q3_test_sub2 = []\n",
        "X_q3_test_sub6 = X_q3[37:37*2]\n",
        "X_q3_test_sub7 = []\n",
        "X_q3_test_sub8 = X_q3[37*2:37*3]\n",
        "\n",
        "X_q1_test = X_q1_test_sub1 + X_q1_test_sub2 + X_q1_test_sub6 + X_q1_test_sub7 + X_q1_test_sub8\n",
        "X_q2_test = X_q2_test_sub1 + X_q2_test_sub2 + X_q2_test_sub6 + X_q2_test_sub7 + X_q2_test_sub8\n",
        "X_q3_test = X_q3_test_sub1 + X_q3_test_sub2 + X_q3_test_sub6 + X_q3_test_sub7 + X_q3_test_sub8\n",
        "\n",
        "\n",
        "X_q1 = X_q1[37*2:37*4] + X_q1[37*6:]\n",
        "X_q2 = X_q2[37:37*3] + X_q2[37*5:]\n",
        "X_q3 = X_q3[37*3:]\n",
        "\n",
        "print(np.shape(X_q1)) # (1406, 224, 224, 3)\n",
        "print(np.shape(X_q2)) # (740, 224, 224, 3)\n",
        "print(np.shape(X_q3)) # (814, 224, 224, 3)\n",
        "print(np.shape(X_q1_test)) # (148, 224, 224, 3)\n",
        "print(np.shape(X_q2_test)) # (111, 224, 224, 3)\n",
        "print(np.shape(X_q3_test)) # (111, 224, 224, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYe8zLeQbep7",
        "outputId": "b9fc93a2-f8d2-4fb0-a07a-35e2beffadd3"
      },
      "outputs": [],
      "source": [
        "# # separate 5 sub's data for test (sub: 6,7,8,9,10)\n",
        "\n",
        "# X_q1_test = X_q1[148:296]\n",
        "# X_q2_test = X_q2[111:222]\n",
        "# X_q3_test = X_q3[37:148]\n",
        "\n",
        "# X_q1 = X_q1[:148] + X_q1[296:]\n",
        "# X_q2 = X_q2[:111] + X_q2[222:]\n",
        "# X_q3 = X_q3[:37] + X_q3[148:]\n",
        "\n",
        "# print(np.shape(X_q1)) # (1406, 224, 224, 3)\n",
        "# print(np.shape(X_q2)) # (740, 224, 224, 3)\n",
        "# print(np.shape(X_q3)) # (814, 224, 224, 3)\n",
        "# print(np.shape(X_q1_test)) # (148, 224, 224, 3)\n",
        "# print(np.shape(X_q2_test)) # (111, 224, 224, 3)\n",
        "# print(np.shape(X_q3_test)) # (111, 224, 224, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACMebGqwSJcq",
        "outputId": "2e685055-92c5-474f-a212-7b99549d31ed"
      },
      "outputs": [],
      "source": [
        "# 12. create video data of first class\n",
        "\n",
        "video_q1 = []\n",
        "subj = 0\n",
        "stride = 1\n",
        "init_frame = 0\n",
        "frame_length = 5 # 5 images per video\n",
        "for subj in range(38): # number of subjects in class = 'lo'\n",
        "  for img in range(37): #stride 1/number of images of each subject / / 38 * (37-5+1) = 1254 total video samples per freq. band (ie. gama)\n",
        "       if img+frame_length>37:\n",
        "          break\n",
        "       tmp_video = X_q1[subj*37+img:subj*37+img+frame_length]\n",
        "       # first 0-5 second 1-6 third 2-7 last 32-37\n",
        "       # 33 movies for each patient. 33*48 movie in total.\n",
        "       video_q1.append(tmp_video)\n",
        "\n",
        "print(np.shape(video_q1)) # The result will be (1254, 5, 224, 224, 3) that is 1254 videos that each of them consist of 5 (224,224,3) images\n",
        "print(img)\n",
        "\n",
        "# 13. create video data of second class\n",
        "\n",
        "video_q2 = []\n",
        "subj = 0\n",
        "stride = 1\n",
        "init_frame = 0\n",
        "frame_length = 5\n",
        "for subj in range(20): # number of subjects\n",
        "  for img in range(37): #stride 1/number of images of each subject\n",
        "       if img+frame_length>37:\n",
        "          break\n",
        "       tmp_video = X_q2[subj*37+img:subj*37+img+frame_length]\n",
        "       video_q2.append(tmp_video)\n",
        "\n",
        "print(np.shape(video_q2)) # (660, 5, 224, 224, 3)\n",
        "print(img)\n",
        "\n",
        "video_q3 = []\n",
        "subj = 0\n",
        "stride = 1\n",
        "init_frame = 0\n",
        "frame_length = 5\n",
        "for subj in range(22): # number of subjects\n",
        "  for img in range(37): #stride 1/number of images of each subject\n",
        "       if img+frame_length>37:\n",
        "          break\n",
        "       tmp_video = X_q3[subj*37+img:subj*37+img+frame_length]\n",
        "       video_q3.append(tmp_video)\n",
        "\n",
        "print(np.shape(video_q3)) # (726, 5, 224, 224, 3)\n",
        "print(img)\n",
        "\n",
        "video_q1_test = []\n",
        "subj = 0\n",
        "stride = 1\n",
        "init_frame = 0\n",
        "frame_length = 5 # 5 images per video\n",
        "for subj in range(4): # number of subjects in class = 'lo'\n",
        "  for img in range(37): #stride 1/number of images of each subject / / 4 * (37-5+1) = 132 total video samples per freq. band (ie. gama)\n",
        "       if img+frame_length>37:\n",
        "          break\n",
        "       tmp_video = X_q1_test[subj*37+img:subj*37+img+frame_length]\n",
        "       # first 0-5 second 1-6 third 2-7 last 32-37\n",
        "       # 33 movies for each patient. 33*48 movie in total.\n",
        "       video_q1_test.append(tmp_video)\n",
        "\n",
        "print(np.shape(video_q1_test)) # The result will be (132, 5, 224, 224, 3) that is 132 videos that each of them consist of 5 (224,224,3) images\n",
        "print(img)\n",
        "\n",
        "# 13. create video data of second class\n",
        "\n",
        "video_q2_test = []\n",
        "subj = 0\n",
        "stride = 1\n",
        "init_frame = 0\n",
        "frame_length = 5\n",
        "for subj in range(3): # number of subjects\n",
        "  for img in range(37): #stride 1/number of images of each subject\n",
        "       if img+frame_length>37:\n",
        "          break\n",
        "       tmp_video = X_q2_test[subj*37+img:subj*37+img+frame_length]\n",
        "       video_q2_test.append(tmp_video)\n",
        "\n",
        "print(np.shape(video_q2_test)) # (99, 5, 224, 224, 3)\n",
        "print(img)\n",
        "\n",
        "video_q3_test = []\n",
        "subj = 0\n",
        "stride = 1\n",
        "init_frame = 0\n",
        "frame_length = 5\n",
        "for subj in range(3): # number of subjects\n",
        "  for img in range(37): #stride 1/number of images of each subject\n",
        "       if img+frame_length>37:\n",
        "          break\n",
        "       tmp_video = X_q3_test[subj*37+img:subj*37+img+frame_length]\n",
        "       video_q3_test.append(tmp_video)\n",
        "\n",
        "print(np.shape(video_q3_test)) # (99, 5, 224, 224, 3)\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDvZg_PtSK1Z",
        "outputId": "5b362cdb-8bfa-42fd-d9d3-e7e2aaf47eb1"
      },
      "outputs": [],
      "source": [
        "# 14. create video_data that is a collection of all classes and then clear memory\n",
        "\n",
        "video_data = video_q1 + video_q2 + video_q3\n",
        "print(np.shape(video_data)) # (2640, 5, 224, 224, 3)\n",
        "\n",
        "video_data_test = video_q1_test + video_q2_test + video_q3_test\n",
        "print(np.shape(video_data_test)) # (330, 5, 224, 224, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_ZU1UCuSOgJ"
      },
      "outputs": [],
      "source": [
        "# 15. dump video_classes as video_data\n",
        "\n",
        "# with open(base_dir+'/video_data_3classes_' + freq_band + '_train', 'wb') as file_pi1:\n",
        "#     pickle.dump(video_data, file_pi1)\n",
        "\n",
        "# with open(base_dir+'/video_data_3classes_' + freq_band + '_test', 'wb') as file_pi1:\n",
        "#     pickle.dump(video_data_test, file_pi1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aJgk3sKSQNn",
        "outputId": "ba11c1be-4ef9-4c2f-ec8f-1adb7475ec9f"
      },
      "outputs": [],
      "source": [
        "# 16. load video_classes from drive\n",
        "\n",
        "# with open(base_dir+'/video_data_3classes_' + freq_band + '_train', 'rb') as f:\n",
        "#     video_data = pickle.load(f)\n",
        "\n",
        "# print(np.shape(video_data)) # (2640, 5, 224, 224, 3)\n",
        "\n",
        "# with open(base_dir+'/video_data_3classes_' + freq_band + '_test', 'rb') as f:\n",
        "#     video_data_test = pickle.load(f)\n",
        "\n",
        "# print(np.shape(video_data_test)) # (330, 5, 224, 224, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnBqaP98SRRp",
        "outputId": "b8fa4008-c45a-4b74-e887-46c5983b763a"
      },
      "outputs": [],
      "source": [
        "# 17. labels for video data\n",
        "\n",
        "q1 = 1254*[0] #lo\n",
        "q2 = 660*[1] #med\n",
        "q3 = 726*[2] #hi\n",
        "\n",
        "labels = q1 + q2 + q3 # set label = 0 for 'lo', label = 1 for 'med' and label = 2 for 'hi'\n",
        "print(np.shape(labels)) # (2640,)\n",
        "\n",
        "q1_test = 132*[0] #lo\n",
        "q2_test = 99*[1] #med\n",
        "q3_test = 99*[2] #hi\n",
        "\n",
        "labels_test = q1_test + q2_test + q3_test # set label = 0 for 'lo', label = 1 for 'med' and label = 2 for 'hi'\n",
        "print(np.shape(labels_test)) # (330,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKLEXB1hyZSR"
      },
      "source": [
        "# Splitting data and balance the train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlVw5fEvSS1X"
      },
      "outputs": [],
      "source": [
        "# 18. splitting train and test video data\n",
        "\n",
        "X_train = video_data\n",
        "X_test = video_data_test\n",
        "Y_train = labels\n",
        "Y_test = labels_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW8bGR1nD28Q",
        "outputId": "450d26a7-4ae5-473c-c521-57bb1816f01c"
      },
      "outputs": [],
      "source": [
        "## Balancing the train data by SMOTE function\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# summarize class distribution\n",
        "print(\"Before oversampling: \",Counter(Y_train))\n",
        "print(np.shape(X_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo-t9_-qEBUi",
        "outputId": "f75cce8f-533a-4d0c-84fc-8ce8de0e7270"
      },
      "outputs": [],
      "source": [
        "# Flatten X_train\n",
        "X_train = np.array(X_train)\n",
        "X_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "print(np.shape(X_flat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8zzilGzEX32",
        "outputId": "d356280c-4e17-417c-eb02-64e8e60cd7e7"
      },
      "outputs": [],
      "source": [
        "# Apply SMOTE to the flattened data\n",
        "smote = SMOTE()\n",
        "X_resampled, Y_resampled = smote.fit_resample(X_flat, Y_train)\n",
        "\n",
        "print(np.shape(X_resampled))\n",
        "print(np.shape(Y_resampled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5iKFPfr4EyJ",
        "outputId": "f5a9dfc9-0fdd-4832-8593-4bb76cd341d5"
      },
      "outputs": [],
      "source": [
        "# Reshape X back to its original shape\n",
        "X_train = X_resampled.reshape(-1, X_train.shape[1], X_train.shape[2], X_train.shape[3], X_train.shape[4])\n",
        "\n",
        "Y_train = Y_resampled\n",
        "# summarize class distribution\n",
        "print(\"After oversampling: \",Counter(Y_resampled)) # Counter({0: 1254, 1: 1254, 2: 1254})\n",
        "\n",
        "\n",
        "print(np.shape(X_train)) # (3762, 5, 224, 224, 3)\n",
        "print(np.shape(Y_train)) # (3762,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6KvS8m1feqU"
      },
      "outputs": [],
      "source": [
        "# clear memory\n",
        "\n",
        "q1 = []\n",
        "q2 = []\n",
        "q3 = []\n",
        "q1_test = []\n",
        "q2_test = []\n",
        "q3_test = []\n",
        "labels = []\n",
        "labels_test = []\n",
        "video_data = []\n",
        "video_data_test = []\n",
        "video_q1 = []\n",
        "video_q2 = []\n",
        "video_q3 = []\n",
        "video_q1_test = []\n",
        "video_q2_test = []\n",
        "video_q3_test = []\n",
        "Images_data = []\n",
        "Images_data_test = []\n",
        "X_q1 = []\n",
        "X_q2 = []\n",
        "X_q3 = []\n",
        "X_q1_test = []\n",
        "X_q2_test = []\n",
        "X_q3_test = []\n",
        "X_resampled = []\n",
        "Y_resampled = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEGQ1t_l3Dxy"
      },
      "outputs": [],
      "source": [
        "# with open(base_dir+'/3classes_' + freq_band + '_X_train', 'wb') as file_pi1:\n",
        "#     pickle.dump(X_train, file_pi1)\n",
        "\n",
        "# with open(base_dir+'/3classes_' + freq_band + '_Y_train', 'wb') as file_pi1:\n",
        "#     pickle.dump(Y_train, file_pi1)\n",
        "\n",
        "# with open(base_dir+'/3classes_' + freq_band + '_X_test', 'wb') as file_pi1:\n",
        "#     pickle.dump(X_test, file_pi1)\n",
        "\n",
        "# with open(base_dir+'/3classes_' + freq_band + '_Y_test', 'wb') as file_pi1:\n",
        "#     pickle.dump(Y_test, file_pi1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M0Woi4O32Tv",
        "outputId": "fc70099b-8cea-44a3-bb21-b40e8c6d05c5"
      },
      "outputs": [],
      "source": [
        "# with open(base_dir+'/3classes_' + freq_band + '_X_train', 'rb') as f:\n",
        "#     X_train = pickle.load(f)\n",
        "\n",
        "# print(np.shape(X_train)) # (3762, 5, 224, 224, 3)\n",
        "\n",
        "# with open(base_dir+'/3classes_' + freq_band + '_Y_train', 'rb') as f:\n",
        "#     Y_train = pickle.load(f)\n",
        "\n",
        "# print(np.shape(Y_train)) # (3762,)\n",
        "\n",
        "# with open(base_dir+'/3classes_' + freq_band + '_X_test', 'rb') as f:\n",
        "#     X_test = pickle.load(f)\n",
        "\n",
        "# print(np.shape(X_test)) # (330, 5, 224, 224, 3)\n",
        "\n",
        "# with open(base_dir+'/3classes_' + freq_band + '_Y_test', 'rb') as f:\n",
        "#     Y_test = pickle.load(f)\n",
        "\n",
        "# print(np.shape(Y_test)) # (330,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gYjfX0aymyZ"
      },
      "source": [
        "# Create and Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K2gqvT35SWCP",
        "outputId": "0dd8317c-d2b7-490f-ccb5-2c5eb1987afc"
      },
      "outputs": [],
      "source": [
        "# Fit CNN+LSTM model with video data\n",
        "\n",
        "# Initialize empty lists to store the training and validation accuracy\n",
        "# train_acc_list = []\n",
        "# val_acc_list = []\n",
        "# train_loss_list = []\n",
        "# val_loss_list = []\n",
        "fold_count=0\n",
        "hist = {}\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "\n",
        "# Use early stopping to halt the training of the model at the right time based on the validation loss\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
        "\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(\n",
        "    model_checkpoint_filepath,\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "for train_index, val_index in skf.split(X_train,Y_train):\n",
        "    fold_count = fold_count + 1\n",
        "\n",
        "    x_train, x_val = np.array(X_train)[train_index], np.array(X_train)[val_index]\n",
        "    y_train, y_val = np.array(Y_train)[train_index], np.array(Y_train)[val_index]\n",
        "    y_train = np_utils.to_categorical(y_train)\n",
        "    y_val = np_utils.to_categorical(y_val)\n",
        "\n",
        "    model = create_model()\n",
        "\n",
        "    history = model.fit(\n",
        "        x_train,y_train,\n",
        "        epochs=50,\n",
        "        batch_size=10,  # I got \"ResourceExhaustedError: Graph execution error\" in batch_size=60\n",
        "        validation_data = (x_val,y_val),\n",
        "        shuffle=True,\n",
        "        callbacks=[early_stopping, checkpoint]\n",
        "        )\n",
        "\n",
        "    # history = model.fit(\n",
        "    #     x_train,y_train,\n",
        "    #     epochs=50,\n",
        "    #     batch_size=10,\n",
        "    #     validation_data = (x_val,y_val),\n",
        "    #     shuffle=True\n",
        "    #     )\n",
        "\n",
        "    plot_results(history)\n",
        "\n",
        "    # Load the best model based on the minimum validation loss\n",
        "    best_model = load_model(model_checkpoint_filepath)\n",
        "\n",
        "    test_acc, conf_mat = test_accuracy(best_model, X_test, Y_test) # this model is trained model (after fitting).\n",
        "\n",
        "    print('fold_'+str(fold_count)+' test_acc: '+str(test_acc))\n",
        "    print('fold_'+str(fold_count)+' confusion matrix: ')\n",
        "    print(conf_mat)\n",
        "    print()\n",
        "\n",
        "    hist['fold'+str(fold_count)+'_history'] = history.history\n",
        "    hist['fold'+str(fold_count)+'_results'] = test_acc\n",
        "\n",
        "    # # save lists of val_acc, acc, val_loss and loss for plotting mean_of_all_folds\n",
        "    # train_acc_list.append(history.history['acc'])\n",
        "    # val_acc_list.append(history.history['val_acc'])\n",
        "\n",
        "    # train_loss_list.append(history.history['loss'])\n",
        "    # val_loss_list.append(history.history['val_loss'])\n",
        "\n",
        "    get_model_metrics(conf_mat)\n",
        "\n",
        "    # save history of each fold\n",
        "    with open(history_dir + '_fold_'+str(fold_count), 'wb') as file_pi1:\n",
        "        pickle.dump(hist, file_pi1)\n",
        "\n",
        "    break\n",
        "# plot_mean_of_all_folds(train_acc_list, val_acc_list, train_loss_list, val_loss_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsLwEpmGyunR"
      },
      "outputs": [],
      "source": [
        "# Load the best model based on the minimum validation loss\n",
        "best_model = load_model(model_checkpoint_filepath)\n",
        "\n",
        "test_acc, conf_mat = test_accuracy(best_model, X_test, Y_test) # this model is trained model (after fitting).\n",
        "\n",
        "print('fold_'+str(fold_count)+' test_acc: '+str(test_acc))\n",
        "print('fold_'+str(fold_count)+' confusion matrix: ')\n",
        "print(conf_mat)\n",
        "print()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
