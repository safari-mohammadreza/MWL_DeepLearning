{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safari-mohammadreza/MWL_DeepLearning/blob/main/CNN%2BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP-vD8-ChDIV"
      },
      "source": [
        "In this code, I reserved data of 5 subjects out of 48 total subjects for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhAbBQKbTFi3"
      },
      "source": [
        "# Initializer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aU4N1kKgQs34"
      },
      "outputs": [],
      "source": [
        "# 1. mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AHuxAJYQ0kf"
      },
      "outputs": [],
      "source": [
        "# 2. set directory of data\n",
        "%cd /content/gdrive/My Drive/your_path/dDTF_images/\n",
        "base_dir='/content/gdrive/My Drive/your_path/dDTF_images/3classes_sub'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFhFEoY7e2rM"
      },
      "outputs": [],
      "source": [
        "# 3. import libraries\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet import ResNet50\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Layer,Dense, Dropout, Input, Activation, TimeDistributed, Reshape\n",
        "from tensorflow.keras.layers import  GRU, Bidirectional\n",
        "from tensorflow.keras.layers import  Conv1D, Conv2D, MaxPooling2D, Flatten, BatchNormalization, LSTM, ZeroPadding2D, GlobalAveragePooling2D, SpatialDropout2D, GlobalMaxPool1D,Convolution1D\n",
        "from tensorflow.keras.callbacks import History\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from natsort import natsorted\n",
        "\n",
        "import cv2\n",
        "import pickle\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhTWfjQWbR2R"
      },
      "outputs": [],
      "source": [
        "# 4. define some methods\n",
        "\n",
        "def smooth_curve(points, factor=0.0):\n",
        "  smoothed_points = []\n",
        "  for point in points:\n",
        "    if smoothed_points:\n",
        "      previous = smoothed_points[-1]\n",
        "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "    else:\n",
        "      smoothed_points.append(point)\n",
        "  return smoothed_points\n",
        "\n",
        "def plot_results(history):\n",
        "  acc = history.history['acc']\n",
        "  val_acc = history.history['val_acc']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "  %matplotlib inline\n",
        "  plt.plot(epochs, smooth_curve(acc), 'bo', label='Training acc')\n",
        "  plt.plot(epochs, smooth_curve(val_acc), 'b', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, smooth_curve(loss), 'bo', label='Training loss')\n",
        "  plt.plot(epochs, smooth_curve(val_loss), 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# def calculate_test_accuracy(X_test, Y_test, model):\n",
        "#   fold_results = {}\n",
        "#   Y_test = np_utils.to_categorical(Y_test)\n",
        "#   predicted_probas = model.predict(np.array(X_test),steps = len(X_test))\n",
        "#   fold_results['predicted_probas'] = predicted_probas\n",
        "#   binary_prediction=[]\n",
        "#   binary_prediction0=[]\n",
        "#   for i in range(len(predicted_probas)):\n",
        "#       binary_prediction0 = 1 if predicted_probas[i,:].argmax()>=0.5 else 0\n",
        "#       # binary_prediction0 = np.round(predicted_probas)\n",
        "#       binary_prediction.append(binary_prediction0)\n",
        "#   fold_results['binary_prediction'] = binary_prediction\n",
        "#   conf_mat = confusion_matrix(binary_prediction, Y_test)\n",
        "#   fold_results['confusion_matrix'] = conf_mat\n",
        "#   acc = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
        "#   fold_results['test_accuracy'] = acc\n",
        "#   print('Overall accuracy: {:.2f} %'.format(acc*100))\n",
        "\n",
        "#   return fold_results\n",
        "\n",
        "\n",
        "# def calculate_best_validation_accuracy(history):\n",
        "#   # Find the index of epoch with the highest validation accuracy\n",
        "#     best_epoch = history.history['val_acc'].index(max(history.history['val_acc']))\n",
        "#     # Get the best validation accuracy\n",
        "#     best_val_acc = history.history['val_acc'][best_epoch]\n",
        "\n",
        "#     print(\"Best validation accuracy: {:.2f}%\".format(best_val_acc * 100))\n",
        "\n",
        "#     return best_val_acc\n",
        "\n",
        "\n",
        "def calculate_test_accuracy_simple(x_test, y_test, model):\n",
        "\n",
        "  Y_test = np_utils.to_categorical(Y_test)\n",
        "  accuracy = model.predict(np.array(X_test),steps = len(X_test))\n",
        "\n",
        "  # _,accuracy = model.evaluate(x_test, to_categorical(y_test.reshape((-1,1))))\n",
        "\n",
        "  print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "\n",
        "def create_model():\n",
        "  conv_base = ResNet50(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
        "  conv_base.trainable = True\n",
        "\n",
        "  model = models.Sequential()\n",
        "  model.add(conv_base)\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(32)) #,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-5)))\n",
        "\n",
        "  cnn = models.Model(model.input, model.output) # dim of output is [number of input,32] -- 32 comes from last later of model. [5, 32]\n",
        "\n",
        "  seq_input = Input(shape=(5,224,224,3))\n",
        "  encoded_sequence = TimeDistributed(cnn)(seq_input) #TimeDistributed, break the video to pictures and feed them to cnn, then concat the results.\n",
        "  encoded_sequence = Bidirectional(LSTM(32, return_sequences=True))(encoded_sequence) #if return_seq = True, it gives a seq in output. in bidirectional LSTM we have 32 sequence in each side\n",
        "\n",
        "  #encoded_sequence = Dropout(rate=0.1)(encoded_sequence)\n",
        "  encoded_sequence = Bidirectional(LSTM(32, return_sequences=False))(encoded_sequence) #if return_seq = False, it gives the last output only\n",
        "  out = Dense(2, activation=\"softmax\")(encoded_sequence)\n",
        "  #out = Convolution1D(1, kernel_size=1, activation=\"sigmoid\", padding=\"same\")(encoded_sequence)\n",
        "\n",
        "  cnn_lstm = models.Model(seq_input, out) # with .Model we give the input and output of the model and it creates the model itself.\n",
        "  cnn_lstm.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(learning_rate=1e-4),metrics=['acc'])\n",
        "\n",
        "  return cnn_lstm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBcOYthMTRQV"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nW7iBMX2p1a"
      },
      "outputs": [],
      "source": [
        "# 5'. load images data from train and test folders\n",
        "\n",
        "hi_s1 = '/content/gdrive/My Drive/your_path/dDTF_images/3classes_sub/theta/hi/s1'\n",
        "train_hi_data = os.listdir(hi_s1)\n",
        "train_hi_data = natsorted(train_hi_data)\n",
        "print(np.array(train_hi_data).shape)\n",
        "\n",
        "hi_s1 = '/content/gdrive/My Drive/your_path/dDTF_images/3classes_sub/theta/hi/s1'\n",
        "train_hi_data = os.listdir(train_hi_dir)\n",
        "train_hi_data = natsorted(train_hi_data)\n",
        "print(np.array(train_hi_data).shape)\n",
        "\n",
        "\n",
        "train_lo_dir = '/content/gdrive/My Drive/your_path/dDTF_images/2classes/gama/train/lo'\n",
        "train_lo_data = os.listdir(train_lo_dir)\n",
        "train_lo_data = natsorted(train_lo_data)\n",
        "print(np.array(train_lo_data).shape)\n",
        "\n",
        "test_hi_dir = '/content/gdrive/My Drive/your_path/dDTF_images/2classes/gama/test/hi'\n",
        "test_hi_data = os.listdir(test_hi_dir)\n",
        "test_hi_data = natsorted(test_hi_data)\n",
        "print(np.array(test_hi_data).shape)\n",
        "\n",
        "test_lo_dir = '/content/gdrive/My Drive/your_path/dDTF_images/2classes/gama/test/lo'\n",
        "test_lo_data = os.listdir(test_lo_dir)\n",
        "test_lo_data = natsorted(test_lo_data)\n",
        "print(np.array(test_lo_data).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ejXqZbNTFti"
      },
      "outputs": [],
      "source": [
        "# 6'. Resize images. this cell may take some time\n",
        "\n",
        "train_hi_resized = []\n",
        "for img in train_hi_data:\n",
        "    with Image.open(train_hi_dir+\"/\"+img) as im:\n",
        "      resized_im = im.resize((224,224))\n",
        "      train_hi_resized.append(resized_im)\n",
        "\n",
        "\n",
        "train_lo_resized = []\n",
        "for img in train_lo_data:\n",
        "    with Image.open(train_lo_dir+\"/\"+img) as im:\n",
        "      resized_im = im.resize((224,224))\n",
        "      train_lo_resized.append(resized_im)\n",
        "\n",
        "\n",
        "test_hi_resized = []\n",
        "for img in test_hi_data:\n",
        "    with Image.open(test_hi_dir+\"/\"+img) as im:\n",
        "      resized_im = im.resize((224,224))\n",
        "      test_hi_resized.append(resized_im)\n",
        "\n",
        "\n",
        "test_lo_resized = []\n",
        "for img in test_lo_data:\n",
        "    with Image.open(test_lo_dir+\"/\"+img) as im:\n",
        "      resized_im = im.resize((224,224))\n",
        "      test_lo_resized.append(resized_im)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bQz1mtE6n9B"
      },
      "outputs": [],
      "source": [
        "# 7. create images_data that is a collection of all classes\n",
        "\n",
        "images_data = train_hi_resized + train_lo_resized + test_hi_resized + test_lo_resized # 1591,1591,185,185"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC6yEwF6FqMX"
      },
      "outputs": [],
      "source": [
        "# 8. dump images_data as Images_48subjects.\n",
        "\n",
        "with open(base_dir+'Images_gama', 'wb') as file_pi1:\n",
        "    pickle.dump(images_data, file_pi1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJKK5vsMAyTR"
      },
      "outputs": [],
      "source": [
        "# 9. load the images_data from drive if you don't wanna run from first cell.\n",
        "\n",
        "with open(base_dir+'Images_gama', 'rb') as f:\n",
        "    images_data = pickle.load(f)\n",
        "\n",
        "\n",
        "print(type(images_data[0]));\n",
        "print(np.shape(images_data[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBeRJQsCxgiE"
      },
      "outputs": [],
      "source": [
        "# 10. convert members to np.array\n",
        "\n",
        "images_data = [np.asarray(img) for img in images_data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JAra1Mdsgrl"
      },
      "source": [
        "# **Prepare the video Samples**\n",
        "prepare video samples from previously loaded Images_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITkbOBmLCNLT"
      },
      "outputs": [],
      "source": [
        "# 11. If you start running from 9th cell you need run this cell to define X_q1 and X_q2\n",
        "\n",
        "train_hi_resized = images_data[:1591]\n",
        "train_lo_resized = images_data[1591:2*1591]\n",
        "test_hi_resized = images_data[2*1591:(2*1591)+185]\n",
        "test_lo_resized = images_data[(2*1591)+185:]\n",
        "\n",
        "print(np.shape(train_hi_resized[0]))\n",
        "print(np.shape(train_hi_resized))\n",
        "print(np.shape(test_hi_resized))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFOTtXm_CSKT"
      },
      "outputs": [],
      "source": [
        "# 12. create video data\n",
        "\n",
        "train_video_hi = []\n",
        "subj = 0\n",
        "stride = 1\n",
        "init_frame = 0\n",
        "frame_length = 5 # 5 images per video\n",
        "for subj in range(43): # number of subjects\n",
        "  for img in range(37): #stride 1/number of images of each subject / / 43 * (37-5+1) = 1419 total video samples per freq. band (ie. gama)\n",
        "       if img + frame_length > 37:\n",
        "          break\n",
        "       tmp_video = train_hi_resized[subj*37+img:subj*37+img+frame_length]\n",
        "       # first 0-5 second 1-6 third 2-7 last 32-37\n",
        "       # 33 movies for each patient. 33*48 movie in total.\n",
        "       train_video_hi.append(tmp_video)\n",
        "\n",
        "print(np.shape(train_video_hi)) # The result will be (1419, 5, 224, 224, 3) that is 1419 videos that each of them consist of 5 (224,224,3) images\n",
        "print(img)\n",
        "\n",
        "\n",
        "train_video_lo = []\n",
        "subj = 0\n",
        "stride = 1\n",
        "init_frame = 0\n",
        "frame_length = 5\n",
        "for subj in range(43):\n",
        "  for img in range(37):\n",
        "       if img + frame_length > 37:\n",
        "          break\n",
        "       tmp_video = train_lo_resized[subj*37+img:subj*37+img+frame_length]\n",
        "       train_video_lo.append(tmp_video)\n",
        "\n",
        "print(np.shape(train_video_lo))\n",
        "print(img)\n",
        "\n",
        "\n",
        "test_video_hi = []\n",
        "subj = 0\n",
        "stride = 1\n",
        "init_frame = 0\n",
        "frame_length = 5\n",
        "for subj in range(5): # data of 5 subjets are reserved for test\n",
        "  for img in range(37):\n",
        "       if img + frame_length > 37:\n",
        "          break\n",
        "       tmp_video = test_hi_resized[subj*37+img:subj*37+img+frame_length]\n",
        "       test_video_hi.append(tmp_video)\n",
        "\n",
        "print(np.shape(test_video_hi))\n",
        "print(img)\n",
        "\n",
        "test_video_lo = []\n",
        "subj = 0\n",
        "stride = 1\n",
        "init_frame = 0\n",
        "frame_length = 5\n",
        "for subj in range(5):\n",
        "  for img in range(37):\n",
        "       if img + frame_length > 37:\n",
        "          break\n",
        "       tmp_video = test_lo_resized[subj*37+img:subj*37+img+frame_length]\n",
        "       test_video_lo.append(tmp_video)\n",
        "\n",
        "print(np.shape(test_video_lo))\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGbqkC9WCd2T"
      },
      "outputs": [],
      "source": [
        "# 14. create video_data that is a collection of all classes\n",
        "\n",
        "video_data = train_video_hi + train_video_lo + test_video_hi + test_video_lo\n",
        "print(np.shape(video_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIJB5Nc3aSwY"
      },
      "outputs": [],
      "source": [
        "# clear memory\n",
        "\n",
        "train_video_hi, train_video_lo, test_video_hi, test_video_lo = [],[],[],[] # we achieved video_data so we clear memory by removing unused variables\n",
        "images_data, train_hi_resized, train_lo_resized, test_hi_resized, test_lo_resized = [], [], [], [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMwHwKH-j9l2"
      },
      "outputs": [],
      "source": [
        "# 15. dump video_classes\n",
        "\n",
        "with open(base_dir+'video_gama', 'wb') as file_pi1:\n",
        "    pickle.dump(video_data, file_pi1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOQbqQKkXflx"
      },
      "outputs": [],
      "source": [
        "# 16. load video_classes from drive\n",
        "\n",
        "with open(base_dir+'video_gama', 'rb') as f:\n",
        "    video_data = pickle.load(f)\n",
        "\n",
        "    print(np.shape(video_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STp84bxJbfAL"
      },
      "outputs": [],
      "source": [
        "# 18'. set train/test data and labels\n",
        "X_train = video_data[:1419*2]\n",
        "X_test = video_data[1419*2:]\n",
        "Y_train = 1419*[1] + 1419*[0] # hi_label=1 , lo_label=0\n",
        "Y_test = 165*[1] + 165*[0]\n",
        "\n",
        "print(np.shape(X_test)) # (165*2, 5, 224, 224, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AavwAeE21NBg"
      },
      "outputs": [],
      "source": [
        "# clear memory\n",
        "\n",
        "Images_data = []\n",
        "video_data = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETCegmYETmP5"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izApGptfws_Y"
      },
      "outputs": [],
      "source": [
        "# Training and validating model\n",
        "\n",
        "x_train = np.array(X_train)\n",
        "x_val = np.array(X_test)\n",
        "y_train = np.array(Y_train)\n",
        "y_val = np.array(Y_test)\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_val = np_utils.to_categorical(y_val)\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "history = model.fit(x_train,y_train,epochs=25, batch_size=10, validation_data = (x_val,y_val), shuffle=True)\n",
        "\n",
        "plot_results(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test and accuracy\n",
        "\n",
        "x_test = np.array(X_test)\n",
        "y_test = np.array(Y_test)\n",
        "\n",
        "calculate_test_accuracy_simple(x_test, y_test, model)"
      ],
      "metadata": {
        "id": "OHd4vtyCvrGO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}